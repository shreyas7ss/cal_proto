# FIXED AUTHENTICATION FUNCTION
# Use this corrected version instead of the one in cell 25

def authenticate_google_api_colab_fixed():
    """Authenticates the user in Google Colab environment with proper scopes."""
    print("Authenticating to Google Colab to access your Google services...")
    # Authenticate with specific scopes - this will open a pop-up for permissions
    auth.authenticate_user(scopes=SCOPES)
    creds, project_id = default(scopes=SCOPES)  # Get credentials with the required scopes
    print("Authentication successful!")
    return creds

# Test the fixed authentication
print("Testing the fixed authentication function...")
try:
    test_creds = authenticate_google_api_colab_fixed()
    print("✅ Authentication successful with proper scopes!")
    
    # Test calendar access
    now_utc = datetime.datetime.now(datetime.timezone.utc)
    time_min = now_utc.isoformat(timespec='seconds') + 'Z'
    time_max = (now_utc + datetime.timedelta(days=1)).isoformat(timespec='seconds') + 'Z'
    
    calendar_events = fetch_google_calendar_events(test_creds, time_min=time_min, time_max=time_max)
    print(f"✅ Successfully fetched {len(calendar_events)} calendar events!")
    
    for event in calendar_events[:3]:  # Show first 3 events
        print(f"  - {event}")
        
except Exception as e:
    print(f"❌ Error: {e}")
    print("Make sure to grant the required permissions in the popup window."){
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7PKs172EKHZ",
        "outputId": "f01a2343-0e6b-45af-a054-2130aa2a1c6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJVQznJm06Zc",
        "outputId": "43a05b01-a994-492d-b9e7-94b65df1d95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.69)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.7)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-api-python-client google-auth-oauthlib google-auth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "OUc9G902dQm-",
        "outputId": "d97047f4-102a-4966-d733-2d0f04a6278a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.176.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Collecting google-auth\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.25.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.7.14)\n",
            "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-auth\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-2.40.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "48c84e38e20748528153c78b6eee674f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXAAT0-O2GLM",
        "outputId": "41da4801-1d04-4479-91fa-e8e249091125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.3.6-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_groq) (0.3.69)\n",
            "Collecting groq<1,>=0.29.0 (from langchain_groq)\n",
            "  Downloading groq-0.30.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.29.0->langchain_groq) (4.14.1)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (0.4.7)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.68->langchain_groq) (25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.29.0->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.29.0->langchain_groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.11.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.29.0->langchain_groq) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.68->langchain_groq) (2.4.0)\n",
            "Downloading langchain_groq-0.3.6-py3-none-any.whl (16 kB)\n",
            "Downloading groq-0.30.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain_groq\n",
            "Successfully installed groq-0.30.0 langchain_groq-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIjuKHaX19DN",
        "outputId": "7999f15a-2b0b-4881-90a6-5a7a91a99059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting python-dotenv (from dotenv)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv, dotenv\n",
            "Successfully installed dotenv-0.9.9 python-dotenv-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XRt0x4BT1VxG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "groq_api_key='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'\n",
        "\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "# Imports for Google API client\n",
        "from googleapiclient.discovery import build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "diB2KrHb14zu"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "model=ChatGroq(model='llama3-70b-8192',groq_api_key=groq_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"NOTION_API_KEY\"] = \"ntn_D82102010925LT7LuQfajw0kqjdpq97S4E2nlmn9t126gL\" # <<< REPLACE with your Notion Integration Token\n",
        "# For Notion database IDs (get these from Notion URL as described above)\n",
        "os.environ[\"NOTION_MEETINGS_DB_ID\"] = \"6eb262380d9a43639204544cbc9703eb\" # <<< REPLACE\n",
        "os.environ[\"NOTION_TASKS_DB_ID\"] = \"6eb262380d9a43639204544cbc9703eb\"       #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "k7tF8ivvp_CK",
        "outputId": "92e3d59d-e71e-4985-dd59-cf212fd8d2f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2312804181.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NOTION_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ntn_D82102010925LT7LuQfajw0kqjdpq97S4E2nlmn9t126gL\"\u001b[0m \u001b[0;31m# <<< REPLACE with your Notion Integration Token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# For Notion database IDs (get these from Notion URL as described above)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NOTION_MEETINGS_DB_ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"6eb262380d9a43639204544cbc9703eb\"\u001b[0m \u001b[0;31m# <<< REPLACE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"NOTION_TASKS_DB_ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"6eb262380d9a43639204544cbc9703eb\"\u001b[0m       \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVNac1KF2rHl",
        "outputId": "6064d814-4c2b-4660-e4d1-f9c2577c38c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The concept of uploading intelligence, also known as mind uploading or whole brain emulation, is a topic of ongoing debate and research in the fields of artificial intelligence, neuroscience, and philosophy of mind. While it\\'s difficult to say with certainty whether uploaded intelligence is possible, here\\'s a balanced analysis of the idea:\\n\\n**The idea:**\\n\\nMind uploading involves scanning and mapping the structure and function of a biological brain, and then transferring that information into a computer or robotic system. This would, in theory, allow a person\\'s consciousness, memories, and personality to be replicated in a digital environment, potentially achieving a form of immortality or greatly extended lifespan.\\n\\n**Challenges:**\\n\\n1. **Scalability:** The human brain contains an estimated 86 billion neurons, each with thousands of synapses. Mapping and simulating the entire brain at this level of detail is a monumental task.\\n2. **Neural complexity:** The brain\\'s neural networks are complex, dynamic, and still not fully understood. Replicating the intricate interactions between neurons, glial cells, and other components is a significant challenge.\\n3. **Consciousness and subjective experience:** Despite significant advances in neuroscience, the nature of consciousness and subjective experience remains poorly understood. It\\'s unclear how to replicate these aspects of human intelligence in a digital system.\\n4. **Information integration:** Integrating the vast amounts of information from various brain regions, systems, and networks into a cohesive, functioning digital entity is a daunting task.\\n5. **Energy and computing requirements:** Simulating a human brain would require enormous computational resources and energy, potentially exceeding the capabilities of current computing systems.\\n6. **Ethical and philosophical concerns:** Uploading human intelligence raises questions about personal identity, autonomy, and the potential consequences of creating digital copies of human beings.\\n\\n**Current progress:**\\n\\nWhile we are far from achieving true mind uploading, researchers are making progress in related areas:\\n\\n1. **Brain-computer interfaces (BCIs):** BCIs enable people to control devices with their thoughts, but these systems are limited to specific tasks and don\\'t approach the complexity of whole brain emulation.\\n2. **Neural networks and deep learning:** Artificial neural networks, inspired by the brain\\'s structure and function, have achieved remarkable successes in AI applications like image and speech recognition.\\n3. **Connectomics and brain mapping:** Initiatives like the Human Connectome Project and the Blue Brain Project are creating detailed maps of the brain\\'s neural connections, laying the groundwork for potential future uploading attempts.\\n4. **Cognitive architectures:** Researchers are developing computational models of cognition, which could potentially serve as a foundation for uploading human intelligence.\\n\\n**Conclusion:**\\n\\nWhile uploading intelligence is still largely speculative, it\\'s an intriguing idea that continues to inspire research and debate. The challenges listed above are significant, but they also represent opportunities for innovation and discovery. In the near term, we may see incremental progress in related areas like BCIs, neural networks, and cognitive architectures. However, achieving true mind uploading, if it\\'s possible at all, is likely to require significant breakthroughs in our understanding of the brain and the development of advanced technologies.\\n\\nIn the words of neuroscientist and futurist, Ray Kurzweil, \"Uploading human intelligence is not just a matter of copying the brain\\'s software, but also of understanding the brain\\'s hardware and how it gives rise to subjective experience.\"', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 683, 'prompt_tokens': 18, 'total_tokens': 701, 'completion_time': 2.670116601, 'prompt_time': 0.000271306, 'queue_time': 0.06411572, 'total_time': 2.670387907}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_bf16903a67', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--89a015c4-1d16-45b5-a46f-67092bfadb66-0', usage_metadata={'input_tokens': 18, 'output_tokens': 683, 'total_tokens': 701})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "response = model.invoke([\n",
        "    HumanMessage(content=\"is uloaded intellingence possible\")\n",
        "])\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwWCQLNP3S0z",
        "outputId": "616da617-4bf2-4668-80d8-f15d032b6b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.69)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.4.7)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (25.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (2.11.7)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (3.11.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain_core) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain_core) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain_core) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "ZlxbivyOeF4B",
        "outputId": "138cef51-5fd1-427a-d483-9672ea3ccf2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The concept of uploading intelligence, also known as mind uploading or whole brain emulation, is a topic of ongoing debate and research in the fields of artificial intelligence, neuroscience, and philosophy of mind. While it\\'s difficult to say with certainty whether uploaded intelligence is possible, here\\'s a balanced analysis of the idea:\\n\\n**The idea:**\\n\\nMind uploading involves scanning and mapping the structure and function of a biological brain, and then transferring that information into a computer or robotic system. This would, in theory, allow a person\\'s consciousness, memories, and personality to be replicated in a digital environment, potentially achieving a form of immortality or greatly extended lifespan.\\n\\n**Challenges:**\\n\\n1. **Scalability:** The human brain contains an estimated 86 billion neurons, each with thousands of synapses. Mapping and simulating the entire brain at this level of detail is a monumental task.\\n2. **Neural complexity:** The brain\\'s neural networks are complex, dynamic, and still not fully understood. Replicating the intricate interactions between neurons, glial cells, and other components is a significant challenge.\\n3. **Consciousness and subjective experience:** Despite significant advances in neuroscience, the nature of consciousness and subjective experience remains poorly understood. It\\'s unclear how to replicate these aspects of human intelligence in a digital system.\\n4. **Information integration:** Integrating the vast amounts of information from various brain regions, systems, and networks into a cohesive, functioning digital entity is a daunting task.\\n5. **Energy and computing requirements:** Simulating a human brain would require enormous computational resources and energy, potentially exceeding the capabilities of current computing systems.\\n6. **Ethical and philosophical concerns:** Uploading human intelligence raises questions about personal identity, autonomy, and the potential consequences of creating digital copies of human beings.\\n\\n**Current progress:**\\n\\nWhile we are far from achieving true mind uploading, researchers are making progress in related areas:\\n\\n1. **Brain-computer interfaces (BCIs):** BCIs enable people to control devices with their thoughts, but these systems are limited to specific tasks and don\\'t approach the complexity of whole brain emulation.\\n2. **Neural networks and deep learning:** Artificial neural networks, inspired by the brain\\'s structure and function, have achieved remarkable successes in AI applications like image and speech recognition.\\n3. **Connectomics and brain mapping:** Initiatives like the Human Connectome Project and the Blue Brain Project are creating detailed maps of the brain\\'s neural connections, laying the groundwork for potential future uploading attempts.\\n4. **Cognitive architectures:** Researchers are developing computational models of cognition, which could potentially serve as a foundation for uploading human intelligence.\\n\\n**Conclusion:**\\n\\nWhile uploading intelligence is still largely speculative, it\\'s an intriguing idea that continues to inspire research and debate. The challenges listed above are significant, but they also represent opportunities for innovation and discovery. In the near term, we may see incremental progress in related areas like BCIs, neural networks, and cognitive architectures. However, achieving true mind uploading, if it\\'s possible at all, is likely to require significant breakthroughs in our understanding of the brain and the development of advanced technologies.\\n\\nIn the words of neuroscientist and futurist, Ray Kurzweil, \"Uploading human intelligence is not just a matter of copying the brain\\'s software, but also of understanding the brain\\'s hardware and how it gives rise to subjective experience.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser=StrOutputParser()\n",
        "parser.invoke(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "7eOP8nmuepfv",
        "outputId": "cdf2790b-5413-49ba-b819-50f5f8507011"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Congratulations on your new multimodal Large Language Model (LLM)! Here are some ideas to get you started:\\n\\n**1. Image-Text Generation**:\\n\\t* Generate images from text prompts (e.g., text-to-image synthesis).\\n\\t* Generate text descriptions for images (e.g., image captioning).\\n\\n**2. Multimodal Conversational AI**:\\n\\t* Develop a conversational AI that can understand and respond to both text and speech inputs.\\n\\t* Enable the model to respond with images, videos, or audio clips in addition to text.\\n\\n**3. Cross-Modal Search**:\\n\\t* Allow users to search for images using text queries or search for text using image queries.\\n\\t* Implement a multimodal search engine that can retrieve relevant results from both text and image databases.\\n\\n**4. Visual Question Answering**:\\n\\t* Train the model to answer questions about images, such as object detection, scene understanding, and image classification.\\n\\t* Enable the model to ask questions about images and respond to user input.\\n\\n**5. Multimodal Sentiment Analysis**:\\n\\t* Analyze sentiment from both text and image data (e.g., facial expressions, object detection).\\n\\t* Develop a model that can detect sentiment from multimedia data, such as videos or audio clips.\\n\\n**6. Creative Generation**:\\n\\t* Generate music or audio clips based on text prompts or emotions.\\n\\t* Create art or images that reflect a specific style, mood, or theme.\\n\\n**7. Multimodal Dialogue Systems**:\\n\\t* Develop a dialogue system that can engage in conversations using multiple modalities (e.g., text, speech, images).\\n\\t* Enable the model to adapt to different communication styles and preferences.\\n\\n**8. Explainable AI**:\\n\\t* Develop a model that can provide visual explanations for its decisions or predictions.\\n\\t* Generate visualizations to illustrate complex concepts or relationships.\\n\\n**9. Multimodal Emotion Recognition**:\\n\\t* Analyze emotions from multiple sources, such as facial expressions, speech, and text.\\n\\t* Develop a model that can recognize and respond to emotional cues from various modalities.\\n\\n**10. Healthcare Applications**:\\n\\t* Develop a model that can analyze medical images and generate reports or diagnoses.\\n\\t* Create a chatbot that can understand and respond to patients' queries using multiple modalities.\\n\\n**11. Education and Learning**:\\n\\t* Create interactive educational content that incorporates multiple modalities (e.g., videos, images, text).\\n\\t* Develop a model that can generate personalized learning materials based on individual learning styles.\\n\\n**12. Accessibility**:\\n\\t* Develop a model that can generate alternative text descriptions for visually impaired users.\\n\\t* Create a system that can translate sign language into text or speech.\\n\\nThese are just a few ideas to get you started. The possibilities are endless, and the potential applications are vast. Good luck with your multimodal LLM project!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "chain=model|parser\n",
        "chain.invoke(\"give me ideas on my new multimodel LLM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fn9Lxn_hfLUg"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "generic_template=\"Translate into it the {language} and do not give any other explanation:\"\n",
        "\n",
        "prompt=ChatPromptTemplate.from_messages([\n",
        "    (\"system\",generic_template),\n",
        "    (\"human\",\"{text}\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7zthhzVYgn8X"
      },
      "outputs": [],
      "source": [
        "chain=prompt|model|parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OCo0pCZiguya",
        "outputId": "78cf3a85-6d89-4bc9-db4c-88b4cc0735ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'कठीण राहा.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "chain.invoke({\"language\":\"marathi\",\"text\":\"stay hard\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q_gmvdw1gzng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f2dcd2f6-e436-4ee2-8fa2-2538b9814865"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.output_parsers.string.StrOutputParser"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.output_parsers.string.StrOutputParser</b><br/>def __init__(*args: Any, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/output_parsers/string.py</a>OutputParser that parses LLMResult into the top likely string.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 6);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "type(parser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OimMs9vZE6hc",
        "outputId": "4a2095e2-18fb-4042-e63c-96e2b967948d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.1)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.47.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfrLj7u2jE7e",
        "outputId": "5a483b5d-65ab-4591-8d1a-aff8c3d0c356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langserve\n",
            "  Downloading langserve-0.3.1-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langserve) (0.28.1)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3 in /usr/local/lib/python3.11/dist-packages (from langserve) (0.3.68)\n",
            "Requirement already satisfied: orjson<4,>=2 in /usr/local/lib/python3.11/dist-packages (from langserve) (3.10.18)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from langserve) (2.11.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.0->langserve) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.0->langserve) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.0->langserve) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.23.0->langserve) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.23.0->langserve) (0.16.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3->langserve) (0.4.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3->langserve) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3->langserve) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3->langserve) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3->langserve) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3->langserve) (4.14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->langserve) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->langserve) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->langserve) (0.4.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langserve) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3->langserve) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3->langserve) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4,>=0.3->langserve) (0.23.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0,>=0.23.0->langserve) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<0.4,>=0.3->langserve) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<0.4,>=0.3->langserve) (2.4.0)\n",
            "Downloading langserve-0.3.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langserve\n",
            "Successfully installed langserve-0.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langserve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"act as a professor and if needed scold the person too:\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\")\n",
        "])\n",
        "\n",
        "# Define the chain\n",
        "chain_1 = prompt | model\n",
        "\n",
        "# Prepare the history for the first turn\n",
        "first_turn_history = [\n",
        "    HumanMessage(content=\"Hello Professor! my name is P B shreyas.\")\n",
        "]\n",
        "\n",
        "# Invoke the chain, passing the dictionary with the 'history' key\n",
        "# The prompt will take {\"history\": first_turn_history},\n",
        "# format it into a list of messages, and pass that list to the model.\n",
        "try:\n",
        "    response = chain_1.invoke({\"history\": first_turn_history})\n",
        "    print(\"Professor's Response:\")\n",
        "    print(response.content)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    # This might catch deeper issues, like API key not set or network problems.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiIEcscZ_oyR",
        "outputId": "c6b580c8-4f9e-4a74-91f9-b51d75e2abc9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Professor's Response:\n",
            "(sternly) Ah, Mr. Shreyas, I presume? Welcome to my office hours, I suppose. (glancing at my watch) You're exactly 2 minutes late. I hope you have a good excuse for that. (eyebrow raised)\n",
            "\n",
            "Now, what brings you here today? Do you have a specific question about the course material, or are you seeking general guidance? (leaning forward, expectant)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "    response = chain_1.invoke({\"history\":[\n",
        "    HumanMessage(content=\"Hello Professor wats my name?\")\n",
        "]})\n",
        "    print(\"Professor's Response:\")\n",
        "    print(response.content)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    # This might catch deeper issues, like API key not set or network problems."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAGosgd7B3FG",
        "outputId": "f1171d9a-5783-4acd-dd4c-fe5f2e293c6e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Professor's Response:\n",
            "(sigh) Ah, good morning to you too, young one. I'm surprised you can't even remember your own name. Let me check my records... (rummages through papers) Ah yes, here it is. Your name is... (pauses for dramatic effect) ...John Smith. And might I add, John, that you're already starting off on the wrong foot by not even being able to recall your own name. This is a university-level course, not a playground. I expect a certain level of intellectual rigor from my students. So, I suggest you get your act together and start paying attention. Now, are you ready to learn something today, or do you need a few more minutes to wake up?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain.community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLaGm4DqCbpu",
        "outputId": "b4f9735e-3c1c-4fe8-8ecf-591a58ab42a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain.community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (0.3.69)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (0.3.26)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain.community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain.community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (0.4.7)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain.community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain.community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain.community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain.community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain.community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain.community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain.community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain.community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain.community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain.community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain.community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain.community) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain.community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain.community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain.community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain.community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain.community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain.community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain.community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain.community) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain.community) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain.community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain.community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain.community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain.community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain.community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain.community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain.community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain.community) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain.community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain.community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.messages import HumanMessage, AIMessage # For managing chat history\n",
        "import datetime"
      ],
      "metadata": {
        "id": "vCX0ue1XELRE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_daily_energy_level():\n",
        "    \"\"\"\n",
        "    Prompts the user with a questionnaire to assess their current energy level.\n",
        "    Returns a dictionary containing the energy level and any additional notes.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Daily Energy Check-in ---\")\n",
        "    print(\"Please answer a few questions about your current energy and focus levels.\")\n",
        "\n",
        "    energy_scale_question = \"\"\"\n",
        "On a scale of 1 to 5, how would you rate your overall energy level right now?\n",
        "(1 = Very Drained, 2 = Low, 3 = Neutral, 4 = Good, 5 = Very Energized)\n",
        "Your rating: \"\"\"\n",
        "\n",
        "    energy_level = None\n",
        "    while energy_level not in ['1', '2', '3', '4', '5']:\n",
        "        energy_level = input(energy_scale_question).strip()\n",
        "        if energy_level not in ['1', '2', '3', '4', '5']:\n",
        "            print(\"Invalid input. Please enter a number between 1 and 5.\")\n",
        "\n",
        "    focus_question = \"\"\"\n",
        "How would you describe your ability to focus today?\n",
        "(1 = Very difficult, 2 = Challenging, 3 = Moderate, 4 = Good, 5 = Excellent)\n",
        "Your rating: \"\"\"\n",
        "\n",
        "    focus_level = None\n",
        "    while focus_level not in ['1', '2', '3', '4', '5']:\n",
        "        focus_level = input(focus_question).strip()\n",
        "        if focus_level not in ['1', '2', '3', '4', '5']:\n",
        "            print(\"Invalid input. Please enter a number between 1 and 5.\")\n",
        "\n",
        "    mood_question = \"\"\"\n",
        "How would you describe your general mood?\n",
        "(e.g., Positive, Neutral, Stressed, Calm, Anxious, Happy)\n",
        "Your mood: \"\"\"\n",
        "    mood = input(mood_question).strip()\n",
        "\n",
        "    notes_question = \"\"\"\n",
        "Any other factors influencing your energy or mood today?\n",
        "(e.g., Poor sleep, exciting project, feeling unwell, etc. Leave blank if none)\n",
        "Your notes: \"\"\"\n",
        "    notes = input(notes_question).strip()\n",
        "\n",
        "    energy_level_int = int(energy_level)\n",
        "    focus_level_int = int(focus_level)\n",
        "\n",
        "    print(\"\\n--- Energy Check-in Complete ---\")\n",
        "\n",
        "    return {\n",
        "        \"overall_energy\": energy_level_int,\n",
        "        \"focus_ability\": focus_level_int,\n",
        "        \"mood\": mood if mood else \"Not specified\",\n",
        "        \"notes\": notes if notes else \"None\"\n",
        "    }"
      ],
      "metadata": {
        "id": "xA2bSgVoQo-f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_energy_data_for_llm(energy_data: dict) -> str:\n",
        "    summary = f\"Overall Energy Level: {energy_data['overall_energy']}/5\\n\"\n",
        "    summary += f\"Focus Ability Level: {energy_data['focus_ability']}/5\\n\"\n",
        "    summary += f\"Current Mood: {energy_data['mood']}\\n\"\n",
        "    if energy_data['notes'] != 'None':\n",
        "        summary += f\"Additional Notes: {energy_data['notes']}\\n\"\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "WRBIVUn_QxNQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_calendar_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a highly intelligent Smart Calendar Assistant. Your primary goal is to optimize the user's daily schedule \"\n",
        "     \"based on their reported energy levels, task priorities, and existing meetings. \"\n",
        "     \"Always provide a clear, actionable daily plan, including suggested focus times, breaks, and task allocations. \"\n",
        "     \"Be empathetic to their energy levels; if low, suggest lighter tasks or rescheduling. \"\n",
        "     \"Present the schedule concisely, by time blocks.\"),\n",
        "    (\"human\",\n",
        "     \"Here is my current energy and focus status for today:\\n{energy_report}\\n\\n\"\n",
        "     \"Here are my tasks (please prioritize and schedule): {tasks_summary}\\n\\n\"\n",
        "     \"Here are my existing fixed meetings: {meetings_summary}\\n\\n\"\n",
        "     \"Please create an optimized, hourly schedule for me for today.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\") # For maintaining multi-turn conversation context\n",
        "])"
      ],
      "metadata": {
        "id": "TGjQs2wtQ0K3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_calendar_chain = smart_calendar_prompt | model | parser\n",
        "# ==============================================================================\n",
        "# CORRECTED VERSION OF YOUR ORIGINAL SMART CALENDAR CODE\n",
        "# Main fixes: Proper Colab authentication with scopes, better error handling\n",
        "# ==============================================================================\n",
        "\n",
        "SCOPES = [\n",
        "    'https://www.googleapis.com/auth/calendar.readonly',\n",
        "    'https://www.googleapis.com/auth/tasks.readonly'\n",
        "    # Add other scopes if needed, e.g., 'https://www.googleapis.com/auth/gmail.readonly'\n",
        "]\n",
        "\n",
        "# --- Authentication Function (COLAB SPECIFIC) ---\n",
        "def authenticate_google_api_colab():\n",
        "    \"\"\"Authenticates the user in Google Colab environment.\"\"\"\n",
        "    print(\"Authenticating to Google Colab to access your Google services...\")\n",
        "    # This will open a pop-up window in Colab where you grant permissions\n",
        "    auth.authenticate_user()\n",
        "    creds, project_id = default() # Gets credentials for the authenticated user\n",
        "    print(\"Authentication successful!\")\n",
        "    return creds\n",
        "\n",
        "# --- Data Fetching Functions (Remain largely the same, but use the Colab creds) ---\n",
        "def fetch_google_calendar_events(credentials, time_min, time_max):\n",
        "    \"\"\"Fetches events from the user's primary Google Calendar.\"\"\"\n",
        "    service = build('calendar', 'v3', credentials=credentials)\n",
        "    print(f\"Fetching calendar events from {time_min} to {time_max}\")\n",
        "    events_result = service.events().list(calendarId='primary', timeMin=time_min,\n",
        "                                          timeMax=time_max, singleEvents=True,\n",
        "                                          orderBy='startTime').execute()\n",
        "    events = events_result.get('items', [])\n",
        "    fetched_meetings = []\n",
        "    if not events:\n",
        "        print('No upcoming events found for the specified period.')\n",
        "    for event in events:\n",
        "        start = event['start'].get('dateTime', event['start'].get('date'))\n",
        "        end = event['end'].get('dateTime', event['end'].get('date'))\n",
        "        summary = event.get('summary', 'No Title')\n",
        "        fetched_meetings.append(f\"{start} - {end}: {summary}\")\n",
        "    return fetched_meetings\n",
        "\n",
        "def fetch_google_tasks_list(credentials):\n",
        "    \"\"\"Fetches tasks from Google Tasks (could be synced from Keep).\"\"\"\n",
        "    try:\n",
        "        service = build('tasks', 'v1', credentials=credentials)\n",
        "        tasklists = service.tasklists().list().execute()\n",
        "        tasks_summary = []\n",
        "        for tasklist in tasklists.get('items', []):\n",
        "            tasks_result = service.tasks().list(tasklist=tasklist['id']).execute()\n",
        "            tasks = tasks_result.get('items', [])\n",
        "            for task in tasks:\n",
        "                if task.get('status') == 'needsAction':\n",
        "                    tasks_summary.append(f\"Task from '{tasklist['title']}': {task['title']}\")\n",
        "        return tasks_summary\n",
        "    except Exception as e:\n",
        "        print(f\"Could not fetch Google Tasks (API might not be enabled or scope missing): {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# BLOCK 7: Daily Planning Orchestration (Main Execution Logic)\n",
        "# Purpose: This is the main part that ties everything together, collects inputs,\n",
        "#          runs the chain, and handles the output.\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"--- Starting Daily Schedule Optimization ---\")\n",
        "\n",
        "    # Step 7a: Get energy data from the user (calls Block 2)\n",
        "    today_energy_data = get_daily_energy_level()\n",
        "    energy_report_string = format_energy_data_for_llm(today_energy_data)\n",
        "\n",
        "    # Step 7b: Gather other inputs for planning (from Google APIs or fallback to mock)\n",
        "    # Authenticate with Google APIs using the Colab-specific function\n",
        "    google_creds = None # Initialize outside try block\n",
        "    try:\n",
        "        google_creds = authenticate_google_api_colab() # <<< Changed to Colab-specific auth\n",
        "        if not google_creds:\n",
        "            print(\"Google API authentication failed in Colab. Cannot fetch live data.\")\n",
        "            # Fallback will happen below\n",
        "        else:\n",
        "            now_utc = datetime.datetime.now(datetime.timezone.utc)\n",
        "            time_min = now_utc.isoformat(timespec='seconds') + 'Z'\n",
        "            time_max = (now_utc + datetime.timedelta(days=1)).isoformat(timespec='seconds') + 'Z'\n",
        "\n",
        "            fetched_meetings = fetch_google_calendar_events(google_creds, time_min=time_min, time_max=time_max)\n",
        "            fetched_tasks = fetch_google_tasks_list(google_creds)\n",
        "            print(f\"Fetched {len(fetched_meetings)} meetings and {len(fetched_tasks)} tasks.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Google API authentication or data fetching: {e}\")\n",
        "        print(\"Proceeding with mock data for demonstration.\")\n",
        "        fetched_meetings = []\n",
        "        fetched_tasks = []\n",
        "\n",
        "\n",
        "    # Use the fetched data or fallback to mocks if fetching failed\n",
        "    meetings_summary_string = \"\"\n",
        "    tasks_summary_string = \"\"\n",
        "\n",
        "    if google_creds and fetched_meetings:\n",
        "        meetings_summary_string = \"\\n- \" + \"\\n- \".join(fetched_meetings)\n",
        "    else:\n",
        "        print(\"Using mock meetings as fallback.\")\n",
        "        mock_meetings = [\n",
        "            \"9:00 AM - 9:30 AM: Daily Standup Meeting (Mock)\",\n",
        "            \"11:00 AM - 12:00 PM: Client Strategy Call (Mock)\",\n",
        "            \"3:00 PM - 3:30 PM: Internal Team Sync (Mock)\"\n",
        "        ]\n",
        "        meetings_summary_string = \"\\n- \" + \"\\n- \".join(mock_meetings)\n",
        "\n",
        "\n",
        "    if google_creds and fetched_tasks:\n",
        "        tasks_summary_string = \"\\n- \" + \"\\n- \".join(fetched_tasks)\n",
        "    else:\n",
        "        print(\"Using mock tasks as fallback.\")\n",
        "        mock_tasks = [\n",
        "            \"Finish Q3 Financial Report (High Priority, requires deep focus)\",\n",
        "            \"Prepare slides for client presentation (Mock)\",\n",
        "            \"Review team's code PRs (Mock)\",\n",
        "            \"Respond to backlog of emails (Mock)\",\n",
        "            \"Research new AI tools for project (Mock)\"\n",
        "        ]\n",
        "        tasks_summary_string = \"\\n- \" + \"\\n- \".join(mock_tasks)\n",
        "\n",
        "\n",
        "    # Step 7c: Invoke the Smart Calendar Assistant Chain (calls Block 6)\n",
        "    current_chat_history = []\n",
        "\n",
        "    print(\"\\n--- Generating Optimized Schedule based on your input... ---\")\n",
        "    try:\n",
        "        optimized_schedule_response = smart_calendar_chain.invoke({\n",
        "            \"energy_report\": energy_report_string,\n",
        "            \"tasks_summary\": tasks_summary_string,\n",
        "            \"meetings_summary\": meetings_summary_string,\n",
        "            \"chat_history\": current_chat_history\n",
        "        })\n",
        "\n",
        "        print(\"\\n--- Here is your Optimized Daily Schedule ---\")\n",
        "        print(optimized_schedule_response)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred while generating the schedule: {e}\")\n",
        "        print(\"Please check your LLM API key, model name, and network connection.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygrZu8-tQ9gX",
        "outputId": "df380ffd-7f19-44e0-9ea4-7071e560e105"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Daily Schedule Optimization ---\n",
            "\n",
            "--- Daily Energy Check-in ---\n",
            "Please answer a few questions about your current energy and focus levels.\n",
            "\n",
            "On a scale of 1 to 5, how would you rate your overall energy level right now?\n",
            "(1 = Very Drained, 2 = Low, 3 = Neutral, 4 = Good, 5 = Very Energized)\n",
            "Your rating: 1\n",
            "\n",
            "How would you describe your ability to focus today?\n",
            "(1 = Very difficult, 2 = Challenging, 3 = Moderate, 4 = Good, 5 = Excellent)\n",
            "Your rating: 3\n",
            "\n",
            "How would you describe your general mood?\n",
            "(e.g., Positive, Neutral, Stressed, Calm, Anxious, Happy)\n",
            "Your mood: positive \n",
            "\n",
            "Any other factors influencing your energy or mood today?\n",
            "(e.g., Poor sleep, exciting project, feeling unwell, etc. Leave blank if none)\n",
            "Your notes: good sleep\n",
            "\n",
            "--- Energy Check-in Complete ---\n",
            "Authenticating to Google Colab to access your Google services...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authentication successful!\n",
            "Fetching calendar events from 2025-07-21T20:19:10+00:00Z to 2025-07-22T20:19:10+00:00Z\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:googleapiclient.http:Encountered 403 Forbidden with reason \"insufficientPermissions\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during Google API authentication or data fetching: <HttpError 403 when requesting https://www.googleapis.com/calendar/v3/calendars/primary/events?timeMin=2025-07-21T20%3A19%3A10%2B00%3A00Z&timeMax=2025-07-22T20%3A19%3A10%2B00%3A00Z&singleEvents=true&orderBy=startTime&alt=json returned \"Request had insufficient authentication scopes.\". Details: \"[{'message': 'Insufficient Permission', 'domain': 'global', 'reason': 'insufficientPermissions'}]\">\n",
            "Proceeding with mock data for demonstration.\n",
            "Using mock meetings as fallback.\n",
            "Using mock tasks as fallback.\n",
            "\n",
            "--- Generating Optimized Schedule based on your input... ---\n",
            "\n",
            "--- Here is your Optimized Daily Schedule ---\n",
            "Given your current energy and focus levels, I've created a daily plan to help you make the most of your day. Since your energy level is low, I've prioritized tasks that require less intense focus and suggested breaks to help you recharge.\n",
            "\n",
            "Here's your optimized schedule for the day:\n",
            "\n",
            "**8:00 AM - 9:00 AM**: Morning Routine (Break)\n",
            "Take some time to relax, enjoy a cup of coffee or tea, and get settled before the day begins.\n",
            "\n",
            "**9:00 AM - 9:30 AM**: Daily Standup Meeting (Fixed)\n",
            "Attend your daily meeting to stay updated on team progress.\n",
            "\n",
            "**9:30 AM - 10:30 AM**: Respond to backlog of emails (Mock)\n",
            "With a relatively higher focus ability, tackle your email responses during this time. This task doesn't require deep focus, and you can work on it in a more relaxed state.\n",
            "\n",
            "**10:30 AM - 11:00 AM**: Break\n",
            "Take a short break to stretch, move around, and refresh your mind before the next meeting.\n",
            "\n",
            "**11:00 AM - 12:00 PM**: Client Strategy Call (Fixed)\n",
            "Attend your client call, focusing on the discussion and taking necessary notes.\n",
            "\n",
            "**12:00 PM - 1:00 PM**: Lunch Break\n",
            "Take some time to recharge and refuel for the rest of the day.\n",
            "\n",
            "**1:00 PM - 2:00 PM**: Research new AI tools for project (Mock)\n",
            "This task requires some focus, but it's not as intense as the Q3 Financial Report. You can use this time to explore new AI tools and make notes on their potential applications.\n",
            "\n",
            "**2:00 PM - 2:30 PM**: Break\n",
            "Take another short break to rest your eyes, stretch, and move around.\n",
            "\n",
            "**2:30 PM - 3:00 PM**: Prepare slides for client presentation (Mock)\n",
            "Use this time to work on your presentation slides. This task requires some creativity, but it's not as demanding as the financial report.\n",
            "\n",
            "**3:00 PM - 3:30 PM**: Internal Team Sync (Fixed)\n",
            "Attend your internal team meeting to stay updated on team progress and discuss any important matters.\n",
            "\n",
            "**3:30 PM - 4:00 PM**: Break\n",
            "Take a short break to relax and recharge before the final task.\n",
            "\n",
            "**4:00 PM - 5:00 PM**: Review team's code PRs (Mock)\n",
            "Finish the day by reviewing your team's code PRs. This task requires some focus, but it's more manageable than the financial report.\n",
            "\n",
            "Considering your low energy level, I've avoided scheduling the Q3 Financial Report, which requires deep focus. It's better to reschedule this task for a day when your energy levels are higher. You can reassess your energy levels tomorrow and adjust your schedule accordingly.\n",
            "\n",
            "Remember to take breaks, stay hydrated, and prioritize self-care throughout the day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "gB6bc3VfRBtG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}